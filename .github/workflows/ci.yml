name: CI

# On every pull request, but only on push to master
on:
  push:
    branches:
    - master
    tags:
    - '*'
  pull_request:
env:
  LATEST_PY_VERSION: '3.9'

jobs:
  tests:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.7', '3.8', '3.9']

    steps:
      - uses: actions/checkout@v2
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v2
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          python -m pip install pre-commit codecov

      - name: Install module
        run: python -m pip install .["test"]

      - name: Run pre-commit
        if: ${{ matrix.python-version == env.LATEST_PY_VERSION }}
        run: pre-commit run --all-files

      - name: Run tests
        run: python -m pytest --cov rio_tiler --cov-report xml --cov-report term-missing --benchmark-skip

      - name: Upload Results
        if: ${{ matrix.python-version == env.LATEST_PY_VERSION }}
        uses: codecov/codecov-action@v1
        with:
          file: ./coverage.xml
          flags: unittests
          name: ${{ matrix.python-version }}
          fail_ci_if_error: false

  benchmark:
    needs: [tests]
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Set up Python
        uses: actions/setup-python@v1
        with:
          python-version: ${{ env.LATEST_PY_VERSION }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          python -m pip install -e .["test"]

      - name: Cache benchmark data
        uses: actions/cache@v2
        with:
          path: ./tests/benchmarks/data/*.tif
          key: ${{ runner.os }}-${{ hashFiles('./tests/benchmarks/__init__.py') }}

      - name: Run Benchmark
        run: python -m pytest --benchmark-only --benchmark-autosave --benchmark-columns 'min, max, mean, median' --benchmark-sort 'min' --benchmark-json output.json

      - name: Store and Compare benchmark result
        uses: benchmark-action/github-action-benchmark@v1
        with:
          name: rio-tiler Benchmarks
          tool: 'pytest'
          output-file-path: output.json
          alert-threshold: '130%'
          comment-on-alert: true
          fail-on-alert: true
          # GitHub API token to make a commit comment
          github-token: ${{ secrets.GITHUB_TOKEN }}
          # Make a commit on `gh-pages` only if master
          auto-push: ${{ github.ref == 'refs/heads/master' }}
          benchmark-data-dir-path: benchmarks

  publish:
    needs: [tests]
    runs-on: ubuntu-latest
    if: startsWith(github.event.ref, 'refs/tags') || github.event_name == 'release'
    steps:
      - uses: actions/checkout@v2
      - name: Set up Python
        uses: actions/setup-python@v1
        with:
          python-version: ${{ env.LATEST_PY_VERSION }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          python -m pip install flit
          python -m pip install .

      - name: Set tag version
        id: tag
        # https://stackoverflow.com/questions/58177786/get-the-current-pushed-tag-in-github-actions
        run: echo ::set-output name=tag::${GITHUB_REF#refs/*/}

      - name: Set module version
        id: module
        run: echo ::set-output name=version::$(python -c 'from importlib.metadata import version; print(version("rio_tiler"))')

      - name: Build and publish
        if: steps.tag.outputs.tag == steps.module.outputs.version
        env:
          FLIT_USERNAME: ${{ secrets.PYPI_USERNAME }}
          FLIT_PASSWORD: ${{ secrets.PYPI_PASSWORD }}
        run: flit publish
