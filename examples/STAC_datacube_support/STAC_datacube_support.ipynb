{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add support for STAC Datacube extension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`rio-tiler` supports GDAL and Xarray Based dataset (DataArray) but supporting both together in a STACReader if tricky because a Xarray based reader might need some `reader_options` provider before openning the dataset. \n",
    "\n",
    "The goal of this notebook is to show how to create a STAC Reader which support the Datacube extension to avoid maximize the compatibility between all the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements\n",
    "\n",
    "To be able to run this notebook you'll need the following requirements:\n",
    "- rio-tiler~=7.0\n",
    "- xarray\n",
    "- rioxarray\n",
    "- h5netcdf\n",
    "- matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Simple NetCDF reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import attr\n",
    "import xarray\n",
    "from morecantile import TileMatrixSet\n",
    "from rio_tiler.io import XarrayReader\n",
    "from rio_tiler.constants import WEB_MERCATOR_TMS\n",
    "\n",
    "\n",
    "@attr.s\n",
    "class NetCDFReader(XarrayReader):\n",
    "    \"\"\"Reader: Open NetCDF file and access DataArray.\"\"\"\n",
    "\n",
    "    src_path: str = attr.ib()\n",
    "    variable: str = attr.ib()\n",
    "\n",
    "    tms: TileMatrixSet = attr.ib(default=WEB_MERCATOR_TMS)\n",
    "\n",
    "    ds: xarray.Dataset = attr.ib(init=False)\n",
    "    input: xarray.DataArray = attr.ib(init=False)\n",
    "\n",
    "    _dims: List = attr.ib(init=False, factory=list)\n",
    "\n",
    "    def __attrs_post_init__(self):\n",
    "        \"\"\"Set bounds and CRS.\"\"\"\n",
    "        self.ds = xarray.open_dataset(self.src_path, decode_coords=\"all\")\n",
    "        da = self.ds[self.variable]\n",
    "\n",
    "        # Make sure we have a valid CRS\n",
    "        crs = da.rio.crs or \"epsg:4326\"\n",
    "        da = da.rio.write_crs(crs)\n",
    "\n",
    "        if \"time\" in da.dims:\n",
    "            da = da.isel(time=0)\n",
    "\n",
    "        self.input = da\n",
    "\n",
    "        super().__attrs_post_init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with NetCDFReader(\"data/dataset_2d.nc\", variable=\"dataset\") as src:\n",
    "    print(src.info())\n",
    "\n",
    "    # NOTE: We can use the preview method because we know the data is relatively small\n",
    "    # but don't use this for large dataset stored on the cloud (because it would download the whole data)\n",
    "    img = src.preview()\n",
    "\n",
    "plt.imshow(img.data_as_image())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Custom STAC reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Set, Type, Tuple, Dict\n",
    "from rio_tiler.types import AssetInfo\n",
    "from rio_tiler.io import STACReader, BaseReader\n",
    "from rio_tiler.io.stac import STAC_ALTERNATE_KEY\n",
    "\n",
    "valid_types = {\n",
    "    \"image/tiff; application=geotiff\",\n",
    "    \"application/x-netcdf\",\n",
    "}\n",
    "\n",
    "\n",
    "@attr.s\n",
    "class CustomSTACReader(STACReader):\n",
    "    include_asset_types: Set[str] = attr.ib(default=valid_types)\n",
    "\n",
    "    def get_asset_list(self) -> List[str]:\n",
    "        \"\"\"Get valid asset list\"\"\"\n",
    "        include = self.include_assets\n",
    "        exclude = self.exclude_assets\n",
    "        include_asset_types = self.include_asset_types\n",
    "        exclude_asset_types = self.exclude_asset_types\n",
    "\n",
    "        assets = []\n",
    "        for asset, asset_info in self.item.get_assets().items():\n",
    "            _type = asset_info.media_type\n",
    "\n",
    "            if exclude and asset in exclude:\n",
    "                continue\n",
    "\n",
    "            if (\n",
    "                _type\n",
    "                and (exclude_asset_types and _type in exclude_asset_types)\n",
    "                or (include and asset not in include)\n",
    "            ):\n",
    "                continue\n",
    "\n",
    "            if (\n",
    "                _type\n",
    "                and (include_asset_types and _type not in include_asset_types)\n",
    "                or (include and asset not in include)\n",
    "            ):\n",
    "                continue\n",
    "\n",
    "            # Here check for the datacube extension\n",
    "            extras = asset_info.extra_fields\n",
    "            if variables := extras.get(\"cube:variables\"):\n",
    "                assets += [f\"{asset}:{v}\" for v in list(variables)]\n",
    "            else:\n",
    "                assets.append(asset)\n",
    "\n",
    "        return assets\n",
    "\n",
    "    def _get_reader(self, asset_info: AssetInfo) -> Tuple[Type[BaseReader], Dict]:\n",
    "        \"\"\"Get Asset Reader.\"\"\"\n",
    "        asset_type = asset_info.get(\"media_type\", None)\n",
    "        if asset_type and asset_type in [\n",
    "            \"application/x-netcdf\",\n",
    "        ]:\n",
    "            return NetCDFReader, asset_info.get(\"reader_options\", {})\n",
    "\n",
    "        return Reader, asset_info.get(\"reader_options\", {})\n",
    "\n",
    "    def _get_asset_info(self, asset: str) -> AssetInfo:\n",
    "        \"\"\"Validate asset names and return asset's info.\n",
    "\n",
    "        Args:\n",
    "            asset (str): STAC asset name.\n",
    "\n",
    "        Returns:\n",
    "            AssetInfo: STAC asset info.\n",
    "\n",
    "        \"\"\"\n",
    "        asset, vrt_options = self._parse_vrt_asset(asset)\n",
    "        if asset not in self.assets:\n",
    "            raise InvalidAssetName(\n",
    "                f\"'{asset}' is not valid, should be one of {self.assets}\"\n",
    "            )\n",
    "\n",
    "        variable = None\n",
    "        if \":\" in asset:\n",
    "            asset, variable = asset.split(\":\")\n",
    "\n",
    "        asset_info = self.item.assets[asset]\n",
    "        extras = asset_info.extra_fields\n",
    "\n",
    "        info = AssetInfo(\n",
    "            url=asset_info.get_absolute_href() or asset_info.href,\n",
    "            name=asset,\n",
    "            metadata=extras if not vrt_options else None,\n",
    "            method_options={},\n",
    "        )\n",
    "\n",
    "        if STAC_ALTERNATE_KEY and extras.get(\"alternate\"):\n",
    "            if alternate := extras[\"alternate\"].get(STAC_ALTERNATE_KEY):\n",
    "                info[\"url\"] = alternate[\"href\"]\n",
    "\n",
    "        if asset_info.media_type:\n",
    "            info[\"media_type\"] = asset_info.media_type\n",
    "\n",
    "        # https://github.com/stac-extensions/file\n",
    "        if head := extras.get(\"file:header_size\"):\n",
    "            info[\"env\"] = {\"GDAL_INGESTED_BYTES_AT_OPEN\": head}\n",
    "\n",
    "        # https://github.com/stac-extensions/raster\n",
    "        if extras.get(\"raster:bands\") and not vrt_options:\n",
    "            bands = extras.get(\"raster:bands\")\n",
    "            stats = [\n",
    "                (b[\"statistics\"][\"minimum\"], b[\"statistics\"][\"maximum\"])\n",
    "                for b in bands\n",
    "                if {\"minimum\", \"maximum\"}.issubset(b.get(\"statistics\", {}))\n",
    "            ]\n",
    "            # check that stats data are all double and make warning if not\n",
    "            if (\n",
    "                stats\n",
    "                and all(isinstance(v, (int, float)) for stat in stats for v in stat)\n",
    "                and len(stats) == len(bands)\n",
    "            ):\n",
    "                info[\"dataset_statistics\"] = stats\n",
    "            else:\n",
    "                warnings.warn(\n",
    "                    \"Some statistics data in STAC are invalid, they will be ignored.\"\n",
    "                )\n",
    "\n",
    "        if vrt_options:\n",
    "            info[\"url\"] = f\"vrt://{info['url']}?{vrt_options}\"\n",
    "\n",
    "        if variable is not None:\n",
    "            info[\"reader_options\"] = {\"variable\": variable}\n",
    "\n",
    "        return info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with CustomSTACReader(\"data/stac_netcdf.json\") as src:\n",
    "    print(src)\n",
    "    print(src.assets)\n",
    "    print(src._get_asset_info(\"netcdf:dataset\"))\n",
    "    img = src.preview(assets=[\"netcdf:dataset\"])\n",
    "\n",
    "plt.imshow(img.data_as_image())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Supporting NetCDF without datacube \n",
    "\n",
    "YOu can also support `NetCDF` files without the datacube extension by customizing the `_get_asset_info` and `_get_reader`. The customization consist by adding a `asset virtual format` (as we do for VRT) in form of `{asset_name}:{variable_name}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Set, Type, Tuple, Dict\n",
    "from rio_tiler.types import AssetInfo\n",
    "from rio_tiler.io import STACReader, BaseReader\n",
    "\n",
    "valid_types = {\n",
    "    \"image/tiff; application=geotiff\",\n",
    "    \"application/x-netcdf\",\n",
    "}\n",
    "\n",
    "\n",
    "@attr.s\n",
    "class CustomSTACReader(STACReader):\n",
    "    include_asset_types: Set[str] = attr.ib(default=valid_types)\n",
    "\n",
    "    def _get_reader(self, asset_info: AssetInfo) -> Tuple[Type[BaseReader], Dict]:\n",
    "        \"\"\"Get Asset Reader.\"\"\"\n",
    "        asset_type = asset_info.get(\"media_type\", None)\n",
    "        if asset_type and asset_type in [\n",
    "            \"application/x-netcdf\",\n",
    "        ]:\n",
    "            return NetCDFReader, asset_info.get(\"reader_options\", {})\n",
    "\n",
    "        return Reader, asset_info.get(\"reader_options\", {})\n",
    "\n",
    "    def _get_asset_info(self, asset: str) -> AssetInfo:\n",
    "        \"\"\"Validate asset names and return asset's info.\n",
    "\n",
    "        Args:\n",
    "            asset (str): STAC asset name.\n",
    "\n",
    "        Returns:\n",
    "            AssetInfo: STAC asset info.\n",
    "\n",
    "        \"\"\"\n",
    "        asset, vrt_options = self._parse_vrt_asset(asset)\n",
    "\n",
    "        # See how this is now before the asset validation\n",
    "        variable = None\n",
    "        if \":\" in asset:\n",
    "            asset, variable = asset.split(\":\")\n",
    "\n",
    "        if asset not in self.assets:\n",
    "            raise InvalidAssetName(\n",
    "                f\"'{asset}' is not valid, should be one of {self.assets}\"\n",
    "            )\n",
    "\n",
    "        asset_info = self.item.assets[asset]\n",
    "        extras = asset_info.extra_fields\n",
    "\n",
    "        info = AssetInfo(\n",
    "            url=asset_info.get_absolute_href() or asset_info.href,\n",
    "            metadata=extras if not vrt_options else None,\n",
    "            name=asset,\n",
    "            method_options={},\n",
    "        )\n",
    "\n",
    "        if STAC_ALTERNATE_KEY and extras.get(\"alternate\"):\n",
    "            if alternate := extras[\"alternate\"].get(STAC_ALTERNATE_KEY):\n",
    "                info[\"url\"] = alternate[\"href\"]\n",
    "\n",
    "        if asset_info.media_type:\n",
    "            info[\"media_type\"] = asset_info.media_type\n",
    "\n",
    "        # https://github.com/stac-extensions/file\n",
    "        if head := extras.get(\"file:header_size\"):\n",
    "            info[\"env\"] = {\"GDAL_INGESTED_BYTES_AT_OPEN\": head}\n",
    "\n",
    "        # https://github.com/stac-extensions/raster\n",
    "        if extras.get(\"raster:bands\") and not vrt_options:\n",
    "            bands = extras.get(\"raster:bands\")\n",
    "            stats = [\n",
    "                (b[\"statistics\"][\"minimum\"], b[\"statistics\"][\"maximum\"])\n",
    "                for b in bands\n",
    "                if {\"minimum\", \"maximum\"}.issubset(b.get(\"statistics\", {}))\n",
    "            ]\n",
    "            # check that stats data are all double and make warning if not\n",
    "            if (\n",
    "                stats\n",
    "                and all(isinstance(v, (int, float)) for stat in stats for v in stat)\n",
    "                and len(stats) == len(bands)\n",
    "            ):\n",
    "                info[\"dataset_statistics\"] = stats\n",
    "            else:\n",
    "                warnings.warn(\n",
    "                    \"Some statistics data in STAC are invalid, they will be ignored.\"\n",
    "                )\n",
    "\n",
    "        if vrt_options:\n",
    "            info[\"url\"] = f\"vrt://{info['url']}?{vrt_options}\"\n",
    "\n",
    "        if variable is not None:\n",
    "            info[\"reader_options\"] = {\"variable\": variable}\n",
    "\n",
    "        return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with CustomSTACReader(\"data/stac_netcdf.json\") as src:\n",
    "    print(src)\n",
    "    print(src.assets)\n",
    "    print(src._get_asset_info(\"netcdf:dataset\"))\n",
    "    img = src.preview(assets=[\"netcdf:dataset\"])\n",
    "\n",
    "plt.imshow(img.data_as_image())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rio-tiler (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
